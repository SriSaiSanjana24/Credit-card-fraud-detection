{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ugSokxLo5Ms"
      },
      "outputs": [],
      "source": [
        "# Importing Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from mlxtend.plotting import plot_learning_curves\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Data into a Dataframe\n",
        "df = pd.read_csv('creditcard.csv')"
      ],
      "metadata": {
        "id": "0htQPeRLpCsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe Data\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "wbPXQ0T0pIKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "kZyO70XwpMnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def countplot_data(data, feature):\n",
        "    '''\n",
        "        Method to compute countplot of given dataframe\n",
        "        Parameters:\n",
        "            data(pd.Dataframe): Input Dataframe\n",
        "            feature(str): Feature in Dataframe\n",
        "    '''\n",
        "    plt.figure(figsize=(10,10))\n",
        "    sns.countplot(x=feature, data=data)\n",
        "    plt.show()\n",
        "\n",
        "def pairplot_data_grid(data, feature1, feature2, target):\n",
        "    '''\n",
        "        Method to construct pairplot of the given feature wrt data\n",
        "        Parameters:\n",
        "            data(pd.DataFrame): Input Dataframe\n",
        "            feature1(str): First Feature for Pair Plot\n",
        "            feature2(str): Second Feature for Pair Plot\n",
        "            target: Target or Label (y)\n",
        "    '''\n",
        "\n",
        "    sns.FacetGrid(data, hue=target, size=6).map(plt.scatter, feature1, feature2).add_legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "OvlboXTHpR_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countplot_data(df, df.Class)"
      ],
      "metadata": {
        "id": "RWEpngjdpUyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pairplot_data_grid(df, \"Time\", \"Amount\", \"Class\")"
      ],
      "metadata": {
        "id": "ShYIY6EupZzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairplot_data_grid(df, \"Amount\", \"Time\", \"Class\")"
      ],
      "metadata": {
        "id": "YVYgnrLHpe5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amount_more = 0\n",
        "amount_less = 0\n",
        "for i in range(df_refine.shape[0]):\n",
        "    if(df_refine.iloc[i][\"Amount\"] < 2500):\n",
        "        amount_less += 1\n",
        "    else:\n",
        "        amount_more += 1\n",
        "print(amount_more)\n",
        "print(amount_less)\n"
      ],
      "metadata": {
        "id": "0IjULHbypf_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_less = (amount_less/df.shape[0])*100\n",
        "percentage_less"
      ],
      "metadata": {
        "id": "P9UZublcpknY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud = 0\n",
        "legitimate = 1\n",
        "for i in range(df_refine.shape[0]):\n",
        "    if(df_refine.iloc[i][\"Amount\"]<2500):\n",
        "        if(df_refine.iloc[i][\"Class\"] == 0):\n",
        "            legitimate += 1\n",
        "        else:\n",
        "            fraud+=1\n",
        "print(fraud)\n",
        "print(legitimate)"
      ],
      "metadata": {
        "id": "7pC5CnCZplEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_refine = df[[\"Time\", \"Amount\", \"Class\"]]\n",
        "sns.pairplot(df_refine, hue=\"Class\", size=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QfatoCS3pnKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Class.value_counts()"
      ],
      "metadata": {
        "id": "ws8l8zIKppQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.FacetGrid(df_refine, hue=\"Class\", size=6).map(sns.distplot,\"Time\").add_legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i9Rwiyaipr1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "df_corr = df.corr()\n",
        "sns.heatmap(df_corr)\n"
      ],
      "metadata": {
        "id": "x7z5DBjJpt_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HCu79s6UpyzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Synthetic Minority Oversampling\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "zZfSqEr7p1je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "mutual_infos = pd.Series(data=mutual_info_classif(X_res, y_res, discrete_features=False, random_state=1)), index=X_train.colu"
      ],
      "metadata": {
        "id": "J9BDY-5yp2Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mutual_infos.sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "Fpq00tv9p6Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(y_res)"
      ],
      "metadata": {
        "id": "dMApxlFrqAGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make use of AUC-ROC Score, Classification Report, Accuracy and F1-Score to evaluate the performance of the classifiers"
      ],
      "metadata": {
        "id": "K64wies1qC5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of Classifiers\n",
        "def grid_eval(grid_clf):\n",
        "    \"\"\"\n",
        "        Method to Compute the best score and parameters computed by grid search\n",
        "        Parameter:\n",
        "            grid_clf: The Grid Search Classifier\n",
        "    \"\"\"\n",
        "    print(\"Best Score\", grid_clf.best_score_)\n",
        "    print(\"Best Parameter\", grid_clf.best_params_)\n",
        "\n",
        "def evaluation(y_test, grid_clf, X_test):\n",
        "    \"\"\"\n",
        "        Method to compute the following:\n",
        "            1. Classification Report\n",
        "            2. F1-score\n",
        "            3. AUC-ROC score\n",
        "            4. Accuracy\n",
        "        Parameters:\n",
        "            y_test: The target variable test set\n",
        "            grid_clf: Grid classifier selected\n",
        "            X_test: Input Feature Test Set\n",
        "    \"\"\"\n",
        "    y_pred = grid_clf.predict(X_test)\n",
        "    print('CLASSIFICATION REPORT')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print('AUC-ROC')\n",
        "    print(roc_auc_score(y_test, y_pred))\n",
        "\n",
        "    print('F1-Score')\n",
        "    print(f1_score(y_test, y_pred))\n",
        "\n",
        "    print('Accuracy')\n",
        "    print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "01_ZWuvlqGZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The parameters of each classifier are different\n",
        "# Hence, we do not make use of a single method and this is not to violate DRY Principles\n",
        "# We set pipelines for each classifier unique with parameters\n",
        "param_grid_sgd = [{\n",
        "    'model__loss': ['log'],\n",
        "    'model__penalty': ['l1', 'l2'],\n",
        "    'model__alpha': np.logspace(start=-3, stop=3, num=20)\n",
        "}, {\n",
        "    'model__loss': ['hinge'],\n",
        "    'model__alpha': np.logspace(start=-3, stop=3, num=20),\n",
        "    'model__class_weight': [None, 'balanced']\n",
        "}]\n",
        "\n",
        "pipeline_sgd = Pipeline([\n",
        "    ('scaler', StandardScaler(copy=False)),\n",
        "    ('model', SGDClassifier(max_iter=1000, tol=1e-3, random_state=1, warm_start=True))\n",
        "])\n",
        "\n",
        "MCC_scorer = make_scorer(matthews_corrcoef)\n",
        "grid_sgd = GridSearchCV(estimator=pipeline_sgd, param_grid=param_grid_sgd, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)\n",
        "\n",
        "\n",
        "grid_sgd.fit(X_res, y_res)"
      ],
      "metadata": {
        "id": "ua_-L2mVqKxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_eval(grid_sgd)"
      ],
      "metadata": {
        "id": "OCljTYDzqNay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test, grid_sgd, X_test)"
      ],
      "metadata": {
        "id": "_XsOt6s7qQOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_rf = Pipeline([\n",
        "    ('model', RandomForestClassifier(n_jobs=-1, random_state=1))\n",
        "])\n",
        "param_grid_rf = {'model__n_estimators': [75]}\n",
        "grid_rf = GridSearchCV(estimator=pipeline_rf, param_grid=param_grid_rf, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)\n",
        "grid_rf.fit(X_res, y_res)"
      ],
      "metadata": {
        "id": "IXKGau8hqSir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_eval(grid_rf)"
      ],
      "metadata": {
        "id": "giy-XibWqU9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test, grid_rf, X_test)"
      ],
      "metadata": {
        "id": "j_OFlnGeqXFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_lr = Pipeline([\n",
        "    ('model', LogisticRegression(random_state=1))\n",
        "])\n",
        "param_grid_lr = {'model__penalty': ['l2'],\n",
        "                 'model__class_weight': [None, 'balanced']}\n",
        "grid_lr = GridSearchCV(estimator=pipeline_lr, param_grid=param_grid_lr, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)\n",
        "grid_lr.fit(X_res, y_res)"
      ],
      "metadata": {
        "id": "M50CT5mdqaWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_eval(grid_lr)"
      ],
      "metadata": {
        "id": "hue_xsCMqcsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test, grid_lr, X_test)"
      ],
      "metadata": {
        "id": "_m7KWvfQqfTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_knn = Pipeline([\n",
        "    ('model', KNeighborsClassifier(n_neighbors=5))\n",
        "])\n",
        "param_grid_knn = {'model__p': [2]}\n",
        "grid_knn = GridSearchCV(estimator=pipeline_knn, param_grid=param_grid_knn, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)\n",
        "grid_knn.fit(X_res, y_res)"
      ],
      "metadata": {
        "id": "C-vfj2JIqhsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_eval(grid_knn)"
      ],
      "metadata": {
        "id": "kPAgfoNCqjp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test, grid_knn, X_test)"
      ],
      "metadata": {
        "id": "c7NBBsBnqnvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n",
        "The K-Nearest Neighbors Classifier tuned with Grid Search with the best parameter being the Euclidean Distance (p=2) outperforms its counterparts to give a test accuracy of nearly 99.8% and a perfect F1-Score with minimal overfitting\n",
        "SMOTE overcomes overfitting by synthetically oversampling minority class labels and is successful to a great degree\n",
        "Summary\n",
        "All Fraud Transactions occur for an amount below 2500. Thus, the bank can infer clearly that the fraud committers try to commit frauds of smaller amounts to avoid suspicion.\n",
        "The fraud transactions are equitable distributed throughout time and there is no clear relationship of time with commiting of fraud.\n",
        "The number of fraud transactions are very few comparted to legitimate transactions and it has to be balanced in order for a fair comparison to prevent the model from overfitting."
      ],
      "metadata": {
        "id": "LzJJjU_1qqfy"
      }
    }
  ]
}